import matplotlib.pyplot as plt;
import pandas as pd
import numpy as np
from sklearn import linear_model
from sklearn.datasets import load_iris


                                                                        # k-means
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler


iris = load_iris()
dir(iris)
iris.feature_names


df = pd.DataFrame(iris.data, columns=iris.feature_names)
df["target"]= iris.target
df.columns
df = df.drop( columns = ["sepal length (cm)", "sepal width (cm)"])
df.columns


plt.scatter(df["petal length (cm)"], df["petal width (cm)"])


km = KMeans(n_clusters=2)
y_predicts = km.fit_predict(df[["petal length (cm)", "petal width (cm)"]])


df["predict"] = y_predicts


df0 = df[df.predict == 0]
df1 = df[df.predict == 1]


plt.scatter(df0["petal length (cm)"], df0["petal width (cm)"], color = "blue")
plt.scatter(df1["petal length (cm)"], df1["petal width (cm)"],color="red")


scaler = MinMaxScaler()
scaler.fit(df[["petal length (cm)"]])
df["petal length (cm)"] = scaler.transform(df[["petal length (cm)"]])
scaler.fit(df[["petal width (cm)"]])
df["petal width (cm)"] = scaler.transform(df[["petal width (cm)"]])


df


km = KMeans(n_clusters=2)
y_predicts = km.fit_predict(df[["petal length (cm)", "petal width (cm)"]])

df["predict"] = y_predicts

df0 = df[df.predict == 0]
df1 = df[df.predict == 1]

plt.scatter(df0["petal length (cm)"], df0["petal width (cm)"], color = "blue")
plt.scatter(df1["petal length (cm)"], df1["petal width (cm)"],color="red")


                                                                        # naive Bayes


from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()



df = pd.read_csv("titanic.csv")
df.head()


from sklearn.preprocessing import LabelEncoder

X = df[['Sex', "Fare", "Pclass"]]
y = df['Survived']

le = LabelEncoder()
X["Sex"] = le.fit_transform(X["Sex"])
X


from sklearn.model_selection import train_test_split


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
gnb = GaussianNB()
gnb.fit(X_train, y_train)
gnb.predict(X_test)


gnb.score(X_test, y_test)


from sklearn.datasets import load_wine

df = load_wine()
dir(df)


X = df.data
y = df.target


from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)
mnb = MultinomialNB()
mnb.fit(X_train, y_train)


mnb.predict(X_test)


mnb.score(X_test, y_test)


                                                                # hyperparameter  tunning


from sklearn.model_selection import cross_val_score



